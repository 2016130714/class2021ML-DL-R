{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "234166cb",
   "metadata": {},
   "source": [
    "# <font color = red>1. 실험 내용 전체 요약</font>\n",
    "* mushroom data에 대해 4가지 모델(OneR, Logistic Regression, MLP, Random Forest)을 적용하였습니다.\n",
    "* parameters 조정 결과 Logistic Regression에서 penalty='none'으로 조정하는 것이 거의 무조건 성능 향상을 보였습니다.\n",
    "* MLP와 Random Forest는 default 모델에서 1.0의 성능이었습니다. parameters 조정을 시도해 봤으나, 성공적이지 않았습니다.\n",
    "* feature selection은 성능 하락의 원인이 되었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1cea86",
   "metadata": {},
   "source": [
    "# <font color = red>2. 데이터에 대한 설명 \n",
    "* url: https://drive.google.com/uc?export=download&id=1u4PEyVWUPODNbCSMCVHDot_8sCy4V8Sk\n",
    "* 위의 url이 안 될 경우: https://archive.ics.uci.edu/ml/datasets/Mushroom\n",
    "* mushroom data set을 선택했습니다. feature는 총 22개고, instance의 수는 총 8124개입니다.\n",
    "* 22개의 class를 바탕으로 예측할 class는 \"먹을 수 있는지\"에 관한 것이며 e(edible)와 p(poisonous)로 구분됩니다.\n",
    "    \n",
    "    \n",
    "* 데이터에 대한 보다 자세한 설명은, 순서상 \"3. (2) 데이터 분포 파악 및 전처리\"에 적었으니 참고 바랍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "6e6e1a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>...</th>\n",
       "      <th>stalk-surface-below-ring</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>y</td>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e</td>\n",
       "      <td>b</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>l</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>y</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>g</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>w</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  class cap-shape cap-surface cap-color bruises odor gill-attachment  \\\n",
       "0     p         x           s         n       t    p               f   \n",
       "1     e         x           s         y       t    a               f   \n",
       "2     e         b           s         w       t    l               f   \n",
       "3     p         x           y         w       t    p               f   \n",
       "4     e         x           s         g       f    n               f   \n",
       "\n",
       "  gill-spacing gill-size gill-color  ... stalk-surface-below-ring  \\\n",
       "0            c         n          k  ...                        s   \n",
       "1            c         b          k  ...                        s   \n",
       "2            c         b          n  ...                        s   \n",
       "3            c         n          n  ...                        s   \n",
       "4            w         b          k  ...                        s   \n",
       "\n",
       "  stalk-color-above-ring stalk-color-below-ring veil-type veil-color  \\\n",
       "0                      w                      w         p          w   \n",
       "1                      w                      w         p          w   \n",
       "2                      w                      w         p          w   \n",
       "3                      w                      w         p          w   \n",
       "4                      w                      w         p          w   \n",
       "\n",
       "  ring-number ring-type spore-print-color population habitat  \n",
       "0           o         p                 k          s       u  \n",
       "1           o         p                 n          n       g  \n",
       "2           o         p                 n          n       m  \n",
       "3           o         p                 k          s       u  \n",
       "4           o         e                 n          a       g  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "path = \"https://drive.google.com/uc?export=download&id=1u4PEyVWUPODNbCSMCVHDot_8sCy4V8Sk\"\n",
    "data = pd.read_csv(path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad60680b",
   "metadata": {},
   "source": [
    "# <font color = red>3. 실험 설계 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6c4e16",
   "metadata": {},
   "source": [
    "### <font color = green>3. (1) 선정한 모델 및 선정 이유\n",
    "* 선정한 모델:\n",
    "** OneR\n",
    "** Logistic Regression\n",
    "** MLP\n",
    "** Random Forest\n",
    "\n",
    "\n",
    "* 선정한 이유: \n",
    "\n",
    "** OneR: 당연한 말이지만, OneR이 좋은 성능을 낼 거라고 기대하고 선택한 것은 아닙니다. 그래도, OneR을 사용하면 가장 구분력 있는 feature를 찾을 수 있을 것이라고 기대했습니다. 이후 모델 선정 및 feature selection 등에 도움을 받기 위해, 데이터 특성에 대한 감을 잡기 위해 선택했습니다.\n",
    "\n",
    "\n",
    "** Logistic Regression: 가장 큰 이유는 binary classification이기 때문입니다. 데이터에서 feature의 수가 다소 많다고 느껴지나, 어쨌든 class는 2개인 데이터입니다. 그렇기 때문에 가장 전형적인 binary classification 방법인 Logistic Regression을 선택했습니다.\n",
    "* 물론 Logistic Regression은 linear하게 classification을 진행하기 때문에 보통 최고의 성능을 보이진 않을 것으로 예상합니다. 그러나 최소한 feature가 linear한 방법으로 충분히 잘 구분되는지는 파악할 수 있을 것입니다. 만약 linear classification으로 충분하지 않은 결가가 나온다면, 이후 좀더 복잡한 non-linear 모델을 통해 성능 향상을 노리겠습니다.\n",
    "\n",
    "** MLP: MLP의 경우 전형적인 non-linear classfication 모델이기 때문에 선택했습니다. Logistic Regression에서 충분한 성능이 나타나지 않는다면 아마 주된 이유는 모델이 linear하기 때문일 것입니다. 그 문제를 해결하기 위해 non-linear하면서도 무난한 MLP를 골랐습니다.\n",
    "\n",
    "** Random Forest: 수업 시간에 배운 바에 의하면, 보통 전형적인 기계학습 중에서 거의 최고의 성능을 보이는 모델 중에 하나가 Random Forest라고 들었습니다. MLP보다 월등한 성능을 기대하며 선택했습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570e9f87",
   "metadata": {},
   "source": [
    "### <font color = green>3. (2) 데이터 분포 파악 및 전처리\n",
    "* 우선 describe method를 바탕으로 데이터의 특성을 최대한 파악하고자 했습니다. 우선 가장 눈에 띄는 점은 class가 binary고, freq값이 8124의 절반 근처 4208이라는 점이었습니다. class가 잘 balanced된 데이터라는 사실을 알 수 있었습니다.\n",
    "\n",
    "\n",
    "* 그 다음 눈에 띄는 점은 freq값이 과도하게 높은 feature들이었습니다. gill-attacthment는 7914, gill-spacing은 6812, veil-type은 8124, veil color은 7924, ring-number는 7488의 freq를 갖고 있었습니다. class가 e: 4208, p: 3916인 데이터에 대해 위와 같이 freq가 6000이 넘어가는 feature들은 높은 확률로 irrelevant할 것이라고 추측할 수 있었습니다. 그래도 일단 임의로 제거하진 않았고, 이럴 것 같다는 경향성만 파악하고 끝냈습니다.\n",
    "\n",
    "\n",
    "* 다만 종류가 1개, freq가 8124인 feature, veil-type은 무조건 확실히 필요 없는 feature일 것입니다. 구분 능력이 말 그대로 전혀 없습니다. 이 feature만큼은 제 판단만을 근거로 임의로 제거해도 된다고 생각했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3eb62251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>...</th>\n",
       "      <th>stalk-surface-below-ring</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>...</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4208</td>\n",
       "      <td>3656</td>\n",
       "      <td>3244</td>\n",
       "      <td>2284</td>\n",
       "      <td>4748</td>\n",
       "      <td>3528</td>\n",
       "      <td>7914</td>\n",
       "      <td>6812</td>\n",
       "      <td>5612</td>\n",
       "      <td>1728</td>\n",
       "      <td>...</td>\n",
       "      <td>4936</td>\n",
       "      <td>4464</td>\n",
       "      <td>4384</td>\n",
       "      <td>8124</td>\n",
       "      <td>7924</td>\n",
       "      <td>7488</td>\n",
       "      <td>3968</td>\n",
       "      <td>2388</td>\n",
       "      <td>4040</td>\n",
       "      <td>3148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       class cap-shape cap-surface cap-color bruises  odor gill-attachment  \\\n",
       "count   8124      8124        8124      8124    8124  8124            8124   \n",
       "unique     2         6           4        10       2     9               2   \n",
       "top        e         x           y         n       f     n               f   \n",
       "freq    4208      3656        3244      2284    4748  3528            7914   \n",
       "\n",
       "       gill-spacing gill-size gill-color  ... stalk-surface-below-ring  \\\n",
       "count          8124      8124       8124  ...                     8124   \n",
       "unique            2         2         12  ...                        4   \n",
       "top               c         b          b  ...                        s   \n",
       "freq           6812      5612       1728  ...                     4936   \n",
       "\n",
       "       stalk-color-above-ring stalk-color-below-ring veil-type veil-color  \\\n",
       "count                    8124                   8124      8124       8124   \n",
       "unique                      9                      9         1          4   \n",
       "top                         w                      w         p          w   \n",
       "freq                     4464                   4384      8124       7924   \n",
       "\n",
       "       ring-number ring-type spore-print-color population habitat  \n",
       "count         8124      8124              8124       8124    8124  \n",
       "unique           3         5                 9          6       7  \n",
       "top              o         p                 w          v       d  \n",
       "freq          7488      3968              2388       4040    3148  \n",
       "\n",
       "[4 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# describe 함수를 통해 데이터의 분포를 파악했습니다.\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3cfd9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요 없는 feature인 veil-type, 그리고 na값을 제거했습니다.\n",
    "data = data.drop([\"veil-type\"], axis=1)\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ba0570",
   "metadata": {},
   "source": [
    "* 또한, head와 describe의 결과 모든 feature가 object type이라는 사실도 파악할 수 있습니다. 따라서 모든 feature에 label encoding또는 one hot encoding을 해서 숫자로 바꿔야 합니다.\n",
    "* label encoding을 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "917137be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>...</th>\n",
       "      <th>stalk-surface-above-ring</th>\n",
       "      <th>stalk-surface-below-ring</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  cap-shape  cap-surface  cap-color  bruises  odor  gill-attachment  \\\n",
       "0      1          5            2          4        1     6                1   \n",
       "1      0          5            2          9        1     0                1   \n",
       "2      0          0            2          8        1     3                1   \n",
       "3      1          5            3          8        1     6                1   \n",
       "4      0          5            2          3        0     5                1   \n",
       "\n",
       "   gill-spacing  gill-size  gill-color  ...  stalk-surface-above-ring  \\\n",
       "0             0          1           4  ...                         2   \n",
       "1             0          0           4  ...                         2   \n",
       "2             0          0           5  ...                         2   \n",
       "3             0          1           5  ...                         2   \n",
       "4             1          0           4  ...                         2   \n",
       "\n",
       "   stalk-surface-below-ring  stalk-color-above-ring  stalk-color-below-ring  \\\n",
       "0                         2                       7                       7   \n",
       "1                         2                       7                       7   \n",
       "2                         2                       7                       7   \n",
       "3                         2                       7                       7   \n",
       "4                         2                       7                       7   \n",
       "\n",
       "   veil-color  ring-number  ring-type  spore-print-color  population  habitat  \n",
       "0           2            1          4                  2           3        5  \n",
       "1           2            1          4                  3           2        1  \n",
       "2           2            1          4                  3           2        3  \n",
       "3           2            1          4                  2           3        5  \n",
       "4           2            1          0                  3           0        1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "for i in data.columns:\n",
    "    data[i] = LabelEncoder().fit_transform(data[i])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2005cb",
   "metadata": {},
   "source": [
    "### <font color = green> 3. (3): Default 모델 훈련\n",
    "* OneR 모델: OneR 모델을 생성하여 어떠한 feature가 단독으로 가장 구분력이 좋은지 파악하고자 했습니다. 우선 best feature를 선택해야 하기 때문에 각 feature의 total errors를 계산했습니다. 그리고, 해당 total errors를 argmin하는 feature를 best feature로 선정하였습니다.\n",
    "* 선택된 best feature에 대해서 OneR 모델을 훈련하였고, 결과는 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf740c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "total_errors = []\n",
    "\n",
    "for col in data.columns[2:]:\n",
    "    error = 0\n",
    "    for val in data[col].unique():\n",
    "        length = len(data[data[col]==val])\n",
    "        error += (length - Counter(data[data[col]==val]['class']).most_common()[0][1])\n",
    "    total_errors.append(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d112e27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cap-color\n"
     ]
    }
   ],
   "source": [
    "best_feature = data.columns[np.argmin(total_errors)]\n",
    "print(best_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4abec4ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cap-color : 4 -> 0\n",
      "cap-color : 9 -> 1\n",
      "cap-color : 8 -> 0\n",
      "cap-color : 3 -> 0\n",
      "cap-color : 2 -> 1\n",
      "cap-color : 5 -> 1\n",
      "cap-color : 0 -> 1\n",
      "cap-color : 7 -> 0\n",
      "cap-color : 1 -> 0\n",
      "cap-color : 6 -> 0\n"
     ]
    }
   ],
   "source": [
    "oneRules = []\n",
    "for val in data[best_feature].unique():\n",
    "    print(f\"{best_feature} : {val}\",\"-> \",end='')\n",
    "    print(Counter(data[data[best_feature]==val]['class']).most_common()[0][0])\n",
    "    oneRules.append((best_feature, val, \n",
    "                    Counter(data[data[best_feature]==val]['class']).most_common()[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a882f056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cap-color', 4, 0),\n",
       " ('cap-color', 9, 1),\n",
       " ('cap-color', 8, 0),\n",
       " ('cap-color', 3, 0),\n",
       " ('cap-color', 2, 1),\n",
       " ('cap-color', 5, 1),\n",
       " ('cap-color', 0, 1),\n",
       " ('cap-color', 7, 0),\n",
       " ('cap-color', 1, 0),\n",
       " ('cap-color', 6, 0)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oneRules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536786fe",
   "metadata": {},
   "source": [
    "* Logistic Regression / MLP / Random Forest 훈련\n",
    "* warning message 방지를 위해 부득이하게 Logistic Regression에서 max_iter=1000을 설정하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "847623a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[['class']]\n",
    "x = data.drop(columns = ['class'])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "LR = LogisticRegression(max_iter = 1000)\n",
    "MLP = MLPClassifier()\n",
    "RF = RandomForestClassifier()\n",
    "\n",
    "# logistic regression model 생성\n",
    "mdl_LR = LR.fit(x_train, y_train.values.ravel())\n",
    "\n",
    "# MLP 모델 생성\n",
    "mdl_MLP = MLP.fit(x_train, y_train.values.ravel())\n",
    "\n",
    "# Random Forest 모델 생성\n",
    "mdl_RF = RF.fit(x_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b580c0cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression score:  0.9495488105004102\n",
      "MLP score:  1.0\n",
      "Random Forest score:  1.0\n"
     ]
    }
   ],
   "source": [
    "# 각 모델의 점수 계산\n",
    "print(\"Logistic Regression score: \", mdl_LR.score(x_test, y_test))\n",
    "print(\"MLP score: \", mdl_MLP.score(x_test, y_test))\n",
    "print(\"Random Forest score: \", mdl_RF.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff410d8",
   "metadata": {},
   "source": [
    "* 긍정적인 현상이긴 하나, 조금은 당황스럽게도 모든 default모델에서 굉장히 좋은 점수가 나왔습니다. 특히 MLP와 Random Forest의 경우에는 1.0점이라는 완벽한 점수가 나왔습니다. 그럼에도 MLP와 Random Forest에 대해 뒤에서 parameters를 조정해보긴 하겠습니다. 점수가 떨어지지 않는지만 확인해보면 되겠지요.\n",
    "\n",
    "\n",
    "* 그렇다면 Logistic Regression을 중점적으로 모델의 성능을 높여보도록 하겠습니다. 또한 feature selection을 거쳐서 최고의 feature로 선택된 것에 대하여 OneR도 다시 적용해보겠습니다.\n",
    "\n",
    "\n",
    "* 혹시 모르니 일단 cross validation의 score도 출력해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9986035e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv_LR score:  [0.93760984 0.93667546 0.96657872 0.93931398 0.94283201]\n",
      "cv_MLP score:  [0.99912127 1.         1.         1.         1.        ]\n",
      "cv_RF score:  [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "score1 = cross_val_score(LR, x_train, y_train.values.ravel(), cv = 5)\n",
    "score2 = cross_val_score(MLP, x_train, y_train.values.ravel(), cv = 5)\n",
    "score3 = cross_val_score(RF, x_train, y_train.values.ravel(), cv = 5)\n",
    "print(\"cv_LR score: \", score1)\n",
    "print(\"cv_MLP score: \", score2)\n",
    "print(\"cv_RF score: \", score3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83595ed3",
   "metadata": {},
   "source": [
    "* cross validation의 score도 전반적으로 유사하게 나왔습니다. Logistic Regression만 조금 편차가 있긴 합니다. 데이터의 variation이 바뀌어도 MLP와 RF는 사실상 1.0의 score을 유지하고 있다는 사실을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f98a95",
   "metadata": {},
   "source": [
    "### <font color = green> 3. (4): parameters 조정\n",
    "* Logistic Regression의 성능을 높이기 위해 parameters를 조정하겠습니다. MLP와 RF에 관해서도 조정을 하되, 점수가 떨어지지 않는지만 관찰하겠습니다.\n",
    "\n",
    "\n",
    "##### Logistic Regression에서 조정할 parameters:\n",
    "* penalty: penalty를 주는 norm 방법 선택\n",
    "* max_iter: 모델 iteration의 최대 횟수 제한\n",
    "\n",
    "\n",
    "* 아래의 반복문을 통해 max_iter을 800에서 1400까지 조정해보겠고, 동시에 penalty를 'none'과 'l2'로 바꿔보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ff40f2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter =  800 / penalty =  none \n",
      "score:  0.9692370795734209 \n",
      "\n",
      "max_iter =  800 / penalty =  l2 \n",
      "score:  0.950369155045119 \n",
      "\n",
      "max_iter =  900 / penalty =  none \n",
      "score:  0.9692370795734209 \n",
      "\n",
      "max_iter =  900 / penalty =  l2 \n",
      "score:  0.950369155045119 \n",
      "\n",
      "max_iter =  1000 / penalty =  none \n",
      "score:  0.9692370795734209 \n",
      "\n",
      "max_iter =  1000 / penalty =  l2 \n",
      "score:  0.950369155045119 \n",
      "\n",
      "max_iter =  1100 / penalty =  none \n",
      "score:  0.9692370795734209 \n",
      "\n",
      "max_iter =  1100 / penalty =  l2 \n",
      "score:  0.950369155045119 \n",
      "\n",
      "max_iter =  1200 / penalty =  none \n",
      "score:  0.9692370795734209 \n",
      "\n",
      "max_iter =  1200 / penalty =  l2 \n",
      "score:  0.950369155045119 \n",
      "\n",
      "max_iter =  1300 / penalty =  none \n",
      "score:  0.9692370795734209 \n",
      "\n",
      "max_iter =  1300 / penalty =  l2 \n",
      "score:  0.950369155045119 \n",
      "\n",
      "max_iter =  1400 / penalty =  none \n",
      "score:  0.9692370795734209 \n",
      "\n",
      "max_iter =  1400 / penalty =  l2 \n",
      "score:  0.950369155045119 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3)\n",
    "\n",
    "for i in range(800, 1500, 100):\n",
    "    for j in ['none', 'l2']:\n",
    "        LR = LogisticRegression(max_iter=i, penalty=j)\n",
    "        mdl_LR = LR.fit(x_train, y_train.values.ravel())\n",
    "        print(\"max_iter = \", str(i), \"/ penalty = \", j, \"\\nscore: \", mdl_LR.score(x_test, y_test), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2665a53d",
   "metadata": {},
   "source": [
    "parameters를 여러 차례 조정해본 결과 가장 좋았던 조정은,\n",
    "* penalty = none\n",
    "\n",
    "이었습니다. max_iter을 꽤 넓은 범위인 800에서 1400까지 돌려봤으나, 성능의 차이가 \"전혀\" 나타나지 않았습니다. \n",
    "\n",
    "반면 penalty = 'none'의 경우 항상 0.969라는 성능 향상을 보장했습니다. max_iter에 상관 없이 말입니다.\n",
    "\n",
    "위의 조정을 근거로 최적의 parameters 조정을 \"max_iter=1000, penalty='none'\"으로 결정하겠습니다. max_iter의 경우 1000으로 설정할 근거는 없으나 그냥 깔끔한 숫자라서 선택했습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4250762e",
   "metadata": {},
   "source": [
    "##### MLP에서 조정할 parameters:\n",
    "* hidden_layer_sizes: hidden layer에 있는 neuron의 수를 결정합니다.\n",
    "* activation: 어떠한 activation function을 쓸지 선택합니다. default는 relu입니다.\n",
    "* learning_rate_init: learning rate의 최초 값을 설정합니다. default는 0.001입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "125bf193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_layer_sizes =  100 / activation =  logistic / learning_rate_init = 0.001 \n",
      "score:  1.0 \n",
      "\n",
      "hidden_layer_sizes =  100 / activation =  logistic / learning_rate_init = 0.003 \n",
      "score:  1.0 \n",
      "\n",
      "hidden_layer_sizes =  100 / activation =  logistic / learning_rate_init = 0.005 \n",
      "score:  1.0 \n",
      "\n",
      "hidden_layer_sizes =  100 / activation =  logistic / learning_rate_init = 0.007 \n",
      "score:  1.0 \n",
      "\n",
      "hidden_layer_sizes =  100 / activation =  logistic / learning_rate_init = 0.009000000000000001 \n",
      "score:  1.0 \n",
      "\n",
      "hidden_layer_sizes =  100 / activation =  relu / learning_rate_init = 0.001 \n",
      "score:  1.0 \n",
      "\n",
      "hidden_layer_sizes =  100 / activation =  relu / learning_rate_init = 0.003 \n",
      "score:  1.0 \n",
      "\n",
      "hidden_layer_sizes =  100 / activation =  relu / learning_rate_init = 0.005 \n",
      "score:  1.0 \n",
      "\n",
      "hidden_layer_sizes =  100 / activation =  relu / learning_rate_init = 0.007 \n",
      "score:  1.0 \n",
      "\n",
      "hidden_layer_sizes =  100 / activation =  relu / learning_rate_init = 0.009000000000000001 \n",
      "score:  1.0 \n",
      "\n",
      "hidden_layer_sizes =  100 / activation =  tanh / learning_rate_init = 0.001 \n",
      "score:  1.0 \n",
      "\n",
      "hidden_layer_sizes =  100 / activation =  tanh / learning_rate_init = 0.003 \n",
      "score:  1.0 \n",
      "\n",
      "hidden_layer_sizes =  100 / activation =  tanh / learning_rate_init = 0.005 \n",
      "score:  1.0 \n",
      "\n",
      "hidden_layer_sizes =  100 / activation =  tanh / learning_rate_init = 0.007 \n",
      "score:  1.0 \n",
      "\n",
      "hidden_layer_sizes =  100 / activation =  tanh / learning_rate_init = 0.009000000000000001 \n",
      "score:  1.0 \n",
      "\n",
      "hidden_layer_sizes =  200 / activation =  logistic / learning_rate_init = 0.001 \n",
      "score:  1.0 \n",
      "\n",
      "hidden_layer_sizes =  200 / activation =  logistic / learning_rate_init = 0.003 \n",
      "score:  1.0 \n",
      "\n",
      "hidden_layer_sizes =  200 / activation =  logistic / learning_rate_init = 0.005 \n",
      "score:  1.0 \n",
      "\n",
      "hidden_layer_sizes =  200 / activation =  logistic / learning_rate_init = 0.007 \n",
      "score:  1.0 \n",
      "\n",
      "hidden_layer_sizes =  200 / activation =  logistic / learning_rate_init = 0.009000000000000001 \n",
      "score:  1.0 \n",
      "\n",
      "hidden_layer_sizes =  200 / activation =  relu / learning_rate_init = 0.001 \n",
      "score:  1.0 \n",
      "\n",
      "hidden_layer_sizes =  200 / activation =  relu / learning_rate_init = 0.003 \n",
      "score:  1.0 \n",
      "\n",
      "hidden_layer_sizes =  200 / activation =  relu / learning_rate_init = 0.005 \n",
      "score:  1.0 \n",
      "\n",
      "hidden_layer_sizes =  200 / activation =  relu / learning_rate_init = 0.007 \n",
      "score:  1.0 \n",
      "\n",
      "hidden_layer_sizes =  200 / activation =  relu / learning_rate_init = 0.009000000000000001 \n",
      "score:  1.0 \n",
      "\n",
      "hidden_layer_sizes =  200 / activation =  tanh / learning_rate_init = 0.001 \n",
      "score:  1.0 \n",
      "\n",
      "hidden_layer_sizes =  200 / activation =  tanh / learning_rate_init = 0.003 \n",
      "score:  1.0 \n",
      "\n",
      "hidden_layer_sizes =  200 / activation =  tanh / learning_rate_init = 0.005 \n",
      "score:  1.0 \n",
      "\n",
      "hidden_layer_sizes =  200 / activation =  tanh / learning_rate_init = 0.007 \n",
      "score:  1.0 \n",
      "\n",
      "hidden_layer_sizes =  200 / activation =  tanh / learning_rate_init = 0.009000000000000001 \n",
      "score:  1.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(100, 300, 100):\n",
    "    for j in ['logistic', 'relu', 'tanh']:\n",
    "        for k in np.arange(0.001, 0.01, 0.002):\n",
    "            MLP = MLPClassifier(hidden_layer_sizes=i, activation=j,\n",
    "                                     learning_rate_init=k)\n",
    "            mdl_MLP = MLP.fit(x_train, y_train.values.ravel())\n",
    "            print(\"hidden_layer_sizes = \", str(i), \"/ activation = \", j, \"/ learning_rate_init =\", str(k),\n",
    "                  \"\\nscore: \", mdl_MLP.score(x_test, y_test), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644efebc",
   "metadata": {},
   "source": [
    "* 많은 조정을 해봤으나, 어떠한 조정에서도 점수가 떨어지는 경우가 없었습니다. 이 정도면 MLP는 mushroom data에 관해 최적의 모델 중 하나라고 결론 내릴 수 있다고 생각합니다.\n",
    "* 또한 특별히 최적의 parameters를 찾지 못했으니, 최적의 경우를 default로 두고 넘어 가겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d08822b",
   "metadata": {},
   "source": [
    "##### Random Forest에서 조정할 parameters:\n",
    "* n_estimators: forest에 사용되는 tree의 수입니다. 이것을 줄여보기도 하면서 점수의 하락이 발생하는지 관찰해보겠습니다.\n",
    "* min_samples_split: forest 내 각 tree를 pruning하기 위해 사용하는 parameters입니다. default=2인데, 이것의 값을 늘려가며, 각 tree를 pruning했을 때의 영향이 긍정적일지, 부정적일지 판단해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "153b8368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators =  10 / min_samples_split =  10 \n",
      "score:  1.0 \n",
      "\n",
      "n_estimators =  10 / min_samples_split =  20 \n",
      "score:  1.0 \n",
      "\n",
      "n_estimators =  10 / min_samples_split =  30 \n",
      "score:  1.0 \n",
      "\n",
      "n_estimators =  20 / min_samples_split =  10 \n",
      "score:  1.0 \n",
      "\n",
      "n_estimators =  20 / min_samples_split =  20 \n",
      "score:  1.0 \n",
      "\n",
      "n_estimators =  20 / min_samples_split =  30 \n",
      "score:  1.0 \n",
      "\n",
      "n_estimators =  30 / min_samples_split =  10 \n",
      "score:  1.0 \n",
      "\n",
      "n_estimators =  30 / min_samples_split =  20 \n",
      "score:  1.0 \n",
      "\n",
      "n_estimators =  30 / min_samples_split =  30 \n",
      "score:  1.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10, 40, 10):\n",
    "    for j in range(10, 40, 10):\n",
    "        RF = RandomForestClassifier(n_estimators=i, min_samples_split=j)\n",
    "        mdl_RF = RF.fit(x_train, y_train.values.ravel())\n",
    "        print(\"n_estimators = \", i, \"/ min_samples_split = \", j, \"\\nscore: \", mdl_RF.score(x_test, y_test), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5292873",
   "metadata": {},
   "source": [
    "* 역시 Random Forest도 parameters에 상관 없이 항상 1.0의 점수를 보였습니다. MLP와 함께 Random Forest역시 mushroom data에 대한 최적의 모델이라고 결론 내리면 좋겠습니다.\n",
    "* 또한 최적의 parameters가 딱히 없기 때문에, 최적의 경우를 그냥 default로 두고 넘어 가겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da182e47",
   "metadata": {},
   "source": [
    "### <font color = green> 3. (5): feature selection\n",
    "feature selection의 목표는 다음과 같습니다.\n",
    "* Logistic Regression의 성능을 조금이라도 더 올리기,\n",
    "*  OneR에 다른 feature를 적용하여 실행해보기.\n",
    "\n",
    "feature selection의 방법으로는 RFE를 사용하겠습니다. 우선 n_features_to_select=1로 설정하여 전체 21개 feature 전부의 ranking을 구할 수 있도록 하겠습니다. 그 다음 sel.ranking_을 통해서 중요한 feature의 ranking을 알아보겠습니다. 최종적으로는, ranking의 순서대로 해당되는 feature의 이름을 출력하겠습니다.\n",
    "* 추가적으로, 출력 과정에서 feature_ranked라는 list를 만들어 feature selection 순서대로 feature를 저장해 놓겠습니다. 뒤에서 최종 모델 선정을 편하게 하기 위한 과정입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e5b01636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19, 18, 15, 10,  1, 21,  9,  4,  2, 13,  5, 11,  8, 17, 14, 20, 16,\n",
       "        6,  3,  7, 12])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RFE를 통해 feature selection\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "select = RFE(RandomForestClassifier(n_estimators=100, random_state=42), n_features_to_select=1)\n",
    "sel = select.fit(x_train, y_train.values.ravel())\n",
    "# feature selection 결과 ranking 출력\n",
    "sel.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c2c3802d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odor\n",
      "gill-color\n",
      "spore-print-color\n",
      "gill-size\n",
      "stalk-root\n",
      "ring-type\n",
      "population\n",
      "stalk-surface-below-ring\n",
      "gill-spacing\n",
      "bruises\n",
      "stalk-surface-above-ring\n",
      "habitat\n",
      "stalk-shape\n",
      "stalk-color-below-ring\n",
      "cap-color\n",
      "ring-number\n",
      "stalk-color-above-ring\n",
      "cap-surface\n",
      "cap-shape\n",
      "veil-color\n",
      "gill-attachment\n"
     ]
    }
   ],
   "source": [
    "# ranking의 순서대로 feature 출력하기\n",
    "temp = list(sel.ranking_)\n",
    "feature_ranked = []\n",
    "n = 1\n",
    "for i in range(21):\n",
    "    index = temp.index(n)\n",
    "    result = data.columns[index+1]\n",
    "    print(result)\n",
    "    n += 1\n",
    "    feature_ranked.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70d9bc9",
   "metadata": {},
   "source": [
    "* 위의 결과는 feature selection을 거쳐 중요한 순서대로 feature를 출력한 것입니다. 즉, 맨 위의 odor가 가장 중요한 feature이고, 맨 아래의 gill-attachment가 가장 중요하지 않은 feature입니다.\n",
    "\n",
    "\n",
    "* 인상적인 점은 OneR 모델 실행을 위해 선택했던 best-feature의 결과가 cap-color이었다는 점입니다. 보다 엄밀한 feature selection의 과정을 거친 결과 cap-color은 하위권에 위치하는 feature고, odor가 1위의 feature라고 알게 되었습니다.\n",
    "\n",
    "* 이 결과를 바탕으로 이제 중요한 feature를 선별하여 다시 모델을 훈련해보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abffc5c",
   "metadata": {},
   "source": [
    "### <font color = green>3. (6): feature selection, parameters 조정을 종합하기\n",
    "** 우선 feature selection 결과 1등인 odor feature를 바탕으로 다시 OneR을 실행해 보겠습니다.\n",
    "\n",
    "** 두 번째로, feature selection에 앞서 parameters를 조정했습니다. 그 결과 선정된 모델과 parameters는 다음과 같습니다.\n",
    "* Logistic Regression: max_iter = 1000, penalty = 'none'\n",
    "* MLP: default\n",
    "* Random Forest: default\n",
    "\n",
    "** 선정된 parameters에 대해 상위 10개의 feature를 바탕으로 다시 학습하여 결과를 출력하겠습니다. feature selection 전후 점수가 상승하는지 하락하는지 관찰해 보겠습니다. 그렇게 한다면 feature selection, parameters 조정을 종합하여 최종 모델을 선별할 수 있을 것입니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d244d3f4",
   "metadata": {},
   "source": [
    "먼저 best feature odor에 대해 OneR을 실행했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "cc55129d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odor : 6 -> 1\n",
      "odor : 0 -> 0\n",
      "odor : 3 -> 0\n",
      "odor : 5 -> 0\n",
      "odor : 2 -> 1\n",
      "odor : 1 -> 1\n",
      "odor : 8 -> 1\n",
      "odor : 7 -> 1\n",
      "odor : 4 -> 1\n"
     ]
    }
   ],
   "source": [
    "best_feature = 'odor'\n",
    "oneRules = []\n",
    "for val in data[best_feature].unique():\n",
    "    print(f\"{best_feature} : {val}\",\"-> \",end='')\n",
    "    print(Counter(data[data[best_feature]==val]['class']).most_common()[0][0])\n",
    "    oneRules.append((best_feature, val, \n",
    "                    Counter(data[data[best_feature]==val]['class']).most_common()[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de03a0e",
   "metadata": {},
   "source": [
    "* 다음으로는 최종 모델을 선정하겠습니다. 앞서 저장해 놓은 feature_ranked list에서 상위 10개의 feature만 사용하여 모델을 다시 훈련하겠습니다.\n",
    "* sel_data라는 DataFrame을 만들어 상위 10개 feature를 저장했고, 그것을 바탕으로 훈련하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "3db3a820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>stalk-root</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>population</th>\n",
       "      <th>stalk-surface-below-ring</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>bruises</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  odor  gill-color  spore-print-color  gill-size  stalk-root  \\\n",
       "0      1     6           4                  2          1           3   \n",
       "1      0     0           4                  3          0           2   \n",
       "2      0     3           5                  3          0           2   \n",
       "3      1     6           5                  2          1           3   \n",
       "4      0     5           4                  3          0           3   \n",
       "\n",
       "   ring-type  population  stalk-surface-below-ring  gill-spacing  bruises  \n",
       "0          4           3                         2             0        1  \n",
       "1          4           2                         2             0        1  \n",
       "2          4           2                         2             0        1  \n",
       "3          4           3                         2             0        1  \n",
       "4          0           0                         2             1        0  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature selection 결과 상위 10개 feature 저장\n",
    "sel_data = pd.DataFrame()\n",
    "sel_data['class'] = data['class']\n",
    "for i in range(10):\n",
    "    sel_data[feature_ranked[i]] = data[feature_ranked[i]]\n",
    "sel_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "7e905227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression score:  0.9458572600492207\n",
      "MLP score:  1.0\n",
      "Random Forest score:  1.0\n"
     ]
    }
   ],
   "source": [
    "# feature selection, parameters 조정이 반영된 모델 생성\n",
    "y = sel_data[['class']]\n",
    "x = sel_data.drop(columns = ['class'])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "LR = LogisticRegression(max_iter = 1000, penalty = 'none')\n",
    "MLP = MLPClassifier()\n",
    "RF = RandomForestClassifier()\n",
    "\n",
    "# logistic regression model 생성\n",
    "mdl_LR = LR.fit(x_train, y_train.values.ravel())\n",
    "\n",
    "# MLP 모델 생성\n",
    "mdl_MLP = MLP.fit(x_train, y_train.values.ravel())\n",
    "\n",
    "# Random Forest 모델 생성\n",
    "mdl_RF = RF.fit(x_train, y_train.values.ravel())\n",
    "\n",
    "# 각 모델의 점수 계산\n",
    "print(\"Logistic Regression score: \", mdl_LR.score(x_test, y_test))\n",
    "print(\"MLP score: \", mdl_MLP.score(x_test, y_test))\n",
    "print(\"Random Forest score: \", mdl_RF.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e63be12",
   "metadata": {},
   "source": [
    "* 의외로, feature selection 결과 상위 10개의 feature를 적용하자 Logistic Regression의 성능이 떨어졌습니다. MLP, Random Forest는 워낙 성능이 좋았기 때문에 떨어지지 않았습니다.\n",
    "* 어쨌든 feature selection은 부정적인 영향을 미쳤다고 판단하겠습니다. 또한 그렇기 때문에 MLP와 Random Forest의 최종 모델 역시 feature selection을 적용하지 않는 것으로 하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459b76b5",
   "metadata": {},
   "source": [
    "### <font color = green> 3. (7): 최종 모델 선정\n",
    "* 최종 모델은 feature selection을 적용하지 않은 것으로 하겠습니다. 또한 위에서 조정한 parameters를 그대로 사용하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "bafe814a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression score:  0.9721082854799016\n",
      "MLP score:  1.0\n",
      "Random Forest score:  1.0\n"
     ]
    }
   ],
   "source": [
    "# feature selection, parameters 조정이 반영된 모델 생성\n",
    "y = data[['class']]\n",
    "x = data.drop(columns = ['class'])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "LR = LogisticRegression(max_iter = 1000, penalty = 'none')\n",
    "MLP = MLPClassifier()\n",
    "RF = RandomForestClassifier()\n",
    "\n",
    "# logistic regression model 생성\n",
    "mdl_LR = LR.fit(x_train, y_train.values.ravel())\n",
    "\n",
    "# MLP 모델 생성\n",
    "mdl_MLP = MLP.fit(x_train, y_train.values.ravel())\n",
    "\n",
    "# Random Forest 모델 생성\n",
    "mdl_RF = RF.fit(x_train, y_train.values.ravel())\n",
    "\n",
    "# 각 모델의 점수 계산\n",
    "print(\"Logistic Regression score: \", mdl_LR.score(x_test, y_test))\n",
    "print(\"MLP score: \", mdl_MLP.score(x_test, y_test))\n",
    "print(\"Random Forest score: \", mdl_RF.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad79140",
   "metadata": {},
   "source": [
    "cross validation 점수는 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "28142e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv_LR score:  [0.96309315 0.95778364 0.97009675 0.96042216 0.96833773]\n",
      "cv_MLP score:  [1.         1.         1.         0.99912049 1.        ]\n",
      "cv_RF score:  [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "score1 = cross_val_score(LR, x_train, y_train.values.ravel(), cv = 5)\n",
    "score2 = cross_val_score(MLP, x_train, y_train.values.ravel(), cv = 5)\n",
    "score3 = cross_val_score(RF, x_train, y_train.values.ravel(), cv = 5)\n",
    "print(\"cv_LR score: \", score1)\n",
    "print(\"cv_MLP score: \", score2)\n",
    "print(\"cv_RF score: \", score3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45660e19",
   "metadata": {},
   "source": [
    "# <font color=red> 4. 실험 결과 분석\n",
    "우선 최종 모델은 다음과 같습니다.\n",
    "* OneR: odor feature로 실행\n",
    "* Logistic Regression: max_iter = 1000, penalty = 'none' \n",
    "--------------------------------------------------------- default model score: 0.949   --> 최종 모델  score: 0.972\n",
    "* MLP: default\n",
    "--------------------------------------------------------- default model score: 1,0   --> 최종 모델  score: 1.0\n",
    "* Random Forest: default --> score: 1.0\n",
    "--------------------------------------------------------- default model score: 1.0   --> 최종 모델  score: 1.0\n",
    "\n",
    "* feature selection은 적용하지 않고 모든 feature를 다 사용한다. (unique한 값이 하나 뿐인 veil-type만 제외)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "* 위의 모델들의 점수는 전부 test set에 대한 평가이며, cross validation의 결과도 크게 다르지 않다는 점을 위에 보였습니다. 조정이 필요 없는 MLP, RF는 논외로 하고, Logistic Regression에 대해서는 상당한 성능 향상을 이뤘습니다.\n",
    "\n",
    "<font color = blue>1. 그렇다면 우선 default 모델에 대해 분석하겠습니다.</font>\n",
    "\n",
    "왜 Logistic Regression은 MLP와 RF에 비해 성능이 좋지 않게 나타났을까요? 답은 데이터에 non-linear한 모델이 좀더 적합하다는 것입니다. 물론 LR의 성능인 0.949도 정말 준수한 건 맞습니다. 그러나 완벽하게 세밀한 분류를 하기 위해서는 확실히 non-linear한 모델이 필요할 것입니다.\n",
    "    \n",
    "<font color = blue>2. ensemble 모델의 성능 분석</font>\n",
    "\n",
    "ensemble 모델인 Random Forest는 1.0의 성능을 보였습니다. 그러나 ensemble이 아닌 MLP역시 1.0을 보였기 때문에, ensemble 모델의 성능이 더 월등함을 밝혀 내지는 못했습니다. 그나마, cross validation을 하면 데이터에 따라 MLP에서 0.99의 점수가 나타나기도 하였으나, 이는 유의미한 성능 차이라고 보기는 어려울 것입니다. mushroom data에서는 단순히 non-linear 모델을 적용하는 것만으로 완벽한 성능을 가져왔으나, 더 복잡한 데이터에서는 분명 ensemble 모델이 더 좋은 성능을 보일 것으로 기대합니다.\n",
    "\n",
    "<font color = blue>3. parameters 조정 분석 (왜 penalty='none'이 무조건 성능 향상을 가져왔나?)</font>\n",
    "    \n",
    "\n",
    "사실상 parameters 조정의 소득은 3개 모델을 통틀어 LR의 penalty='none' 뿐 입니다. 아쉽긴 하지만 MLP와 RF에 관해서는 parameters 조정이 필요하지 않았습니다. 성능을 깎아먹는 parameters라도 찾아보려고 하였으나, 모델의 성능이 너무 좋아서 악조건에서도 그대로 1.0의 점수를 유지했습니다.\n",
    "그래도 Logistic Regression의 penalty='none'은 거의 무조건 성능 향상을 가져 왔습니다.\n",
    "* penalty='none'이 성능을 향상시킨 이유를 추론하자면 다음과 같습니다. 제가 다른 수업에서 배운 바에 의하면 L1-norm, L2-norm 등은 regularization 방법입니다. 즉 모델을 generalize하고, overfitting을 줄이는 방법이라고 배웠습니다. generalize한다는 것에 관점을 바꾸면, \"noise를 넣는다, 혼란을 준다\"라고 볼 수 있을 것 같습니다. 정말 overfitting이 발생한 상황이라면 이것은 분명 도움이 됩니다. 그리고 대부분 실생활의 데이터는 이번 실험의 데이터보다 훨씬 광범위하고 복잡하기 때문에 overfitting이 흔하게 발생할 것으로 예상합니다.\n",
    "* 그러나 이번 실험에서는 overfitting이 거의 전혀 일어나지 않았다고 판단했습니다. 실제로 점수를 봤을 때 train set의 점수가 특별히 월등히 높거나 그렇지 않았습니다. 이처럼 overfitting이 거의 전혀 일어나지 않은, 성능이 매우 우수한 모델에 대해서는 regularization이 오히려 방해가 될 수 있다고 생각했습니다. \n",
    "* 쉽게 말해, 그냥 default 상태에서 잘 학습하는 Logistic Regression 모델에, 괜히 noise를 넣어서 오히려 학습을 방해한 셈이죠. penalty='none'을 했다는 것은 곧 그 noise를 제거한 것이라고 생각했습니다. 그렇기 때문에 확실히 성능 향상을 가져왔다고 추론했습니다.\n",
    "\n",
    "<font color = blue>4. feature selection 분석</font>\n",
    " \n",
    "feature selection을 적용하자 Logistic Regression의 성능이 0.948까지 낮아졌습니다. parameters의 조정을 마쳐 0.972의 성능까지 기록한 모델에 적용한 것이니, 하락이 상당히 크다고 볼 수 있습니다.\n",
    "* 수업 시간에 feature selection은 거의 무조건 성능 향상을 불러올 것이라고 배웠고, 저도 그런 결과가 나올 것이라고 예상하였습니다. 그래서 왜 성능 향상이 나타나지 않았는지 나름대로 곰곰이 생각해봤습니다. 제가 내린 답은, \"모델의 성능이 너무 좋기 때문\"입니다.\n",
    "\n",
    "* 모델의 성능이 0.95이상 1.0수준으로 말도 안되게 좋은 상황이라면, 그것의 원인은 전적으로 모델 자체에만 있다고 보긴 힘들 것입니다. 그만큼 feature도 성능에 크게 기여한 것이라고 봐야 할 것입니다. 즉 feature과 모델의 상호작용이 완벽한 점수를 이뤄냈다고 생각했습니다. \n",
    "* 이러한 상황에서 굳이 상대적으로 기여도가 낮은 feature를 제거하는 게 부정적인 영향을 미쳤습니다. 기여도가 낮지만 0.948을 0.972로 만드는 작은 기여는 하고 있었던 것이겠지요. 상대적으로는 irrelevant하나, 어쨌든 조금이라도 긍정적인 영향을 주고 있는 feature들을 제거한 것이었습니다.\n",
    "    \n",
    "<font color = blue> 5. 더 실험해보고 싶은 사항</font>\n",
    "* 실험을 마치고 분석하며 생각해보니, feature selection의 개수를 10개로 한 것이 성능 하락의 원인이었나도 추측해보게 되었습니다. 막연히 21개의 feature의 절반인 10개를 선택한 것이었고, 그 막연한 선택조차도 긍정적인 영향을 줄 것으로 기대했습니다.\n",
    "* 그러나 성능 하락이 관찰되었습니다. 이러한 경우 다음부터는 feature selection의 개수를 바꿔가며 분석해 보는 것이 좋겠다고 생각했습니다. 10개를 고정하지 말고, [5, 6, 7, .... 20] 이렇게 숫자를 바꿔가면서 최적의 feature 개수까지 찾아봤으면 어땠을까 싶습니다. 그렇게 했다면 Logistic Regression의 0.972를 조금이라도 더 올려볼 수 있지 않았을까 싶습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a534d33",
   "metadata": {},
   "source": [
    "# <font color=red> 5. 결론 </font>\n",
    "* mushroom data에 대해 4가지 모델(OneR, Logistic Regression, MLP, Random Forest)을 적용하였습니다.\n",
    "* parameters 조정 결과 Logistic Regression에서 penalty='none'으로 조정하는 것이 거의 무조건 성능 향상을 보였습니다.\n",
    "* MLP와 Random Forest는 default 모델에서 1.0의 성능이었습니다. parameters 조정을 시도해 봤으나, 성공적이지 않았습니다.\n",
    "* feature selection은 성능 하락의 원인이 되었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bfa0fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
